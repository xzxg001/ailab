{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c9fda4c-4d10-44b0-86d9-0187ae18ed6a",
   "metadata": {},
   "source": [
    "### 使用BertTokenizer进行文本向量化\n",
    "### 使用opensmile提取音频特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3061bfb7-790b-40e4-84a5-21777e581d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import opensmile\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eda0a5-9aea-4c99-b3ea-a90cf4d4c962",
   "metadata": {},
   "source": [
    "## 1、构造特征提取函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037185c3-14fb-48b7-894e-8870d1786124",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 文本向量化函数\n",
    "## text_list 文本内容的list\n",
    "## 返回一个字典，{'input_ids':value, 'token_type_ids':value, 'attention_mask':value},每个元素的长度等于len(text_list)\n",
    "## \"input_ids\"-词转换为数字后的序列 'token_type_ids'-标记一段文本中不同句子的序号 'attention_mask'-标记填充位置的序号 \n",
    "## reference: https://huggingface.co/docs/transformers/main/en/glossary\n",
    "def text_tokenize(text_list): \n",
    "    tokenizer = BertTokenizer.from_pretrained('./bert-base-uncased',do_lower_case=True)\n",
    "    encoded_text = tokenizer.batch_encode_plus(\n",
    "        text_list,\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "        pad_to_max_length=True,\n",
    "        max_length=256,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    return encoded_text\n",
    "## 'input_ids' 'token_type_ids' 'attention_mask'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8244820c-61db-4956-ac2a-70826f38f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 文本向量化示例\n",
    "temp_txt_list = [\"Hello,my name is Jerry.\",\"Hello,my name is Tom.\"]\n",
    "temp_coded_txt = text_tokenize(temp_txt_list)\n",
    "print(type(temp_coded_txt),len(temp_coded_txt),len(temp_coded_txt[\"input_ids\"]))\n",
    "len(temp_coded_txt[\"token_type_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad48b1ae-a698-4e18-8739-d154c0e9a07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 音频特征提取函数\n",
    "## file_list:音频文件路径的列表  list类型\n",
    "## 返回值numpy.ndarray  形状:(len(file_list),88)\n",
    "def extract_audio_feature(file_list):\n",
    "    print(\"请耐心等待特征提取完！\")\n",
    "    smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals)\n",
    "    feature = []\n",
    "    for n,file in enumerate(file_list):\n",
    "        y = smile.process_file(file)\n",
    "        y = y.to_numpy().reshape(-1)\n",
    "        feature.append(y)\n",
    "        if (n+1)%100 == 0:\n",
    "            print(f\"当前进度{n+1}/{len(file_list)}\")\n",
    "    print(\"此次特征提取已结束\")\n",
    "    print(\"-------------------------------\")\n",
    "    feature = np.stack(feature,axis = 0)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169d694d-8d16-4949-89b2-9030d6698f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 音频特征提取示例\n",
    "file = \"./train/Ses01F_impro01_F000.wav\"\n",
    "audio_feature = extract_audio_feature([file])\n",
    "print(type(audio_feature),audio_feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1406f0d-5ecc-489d-9395-46818f35961c",
   "metadata": {},
   "source": [
    "## 2、读入CSV文件示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2996d3bc-d357-4668-a624-a76d3f4fe372",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 读入csv文件示例\n",
    "## 由于我们的csv文件使用\"#\"分隔，需要定义sep参数为\"#\",否则会读取失败！！！\n",
    "train_csv = pd.read_csv(\"./CSVfile/train.csv\",sep=\"#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05c3893-b7e7-44e1-b724-ce3f8b2d2540",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv.text.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743c4b1c-beb9-4802-8ad4-eaff49fa7f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 快速查看前5条数据\n",
    "train_csv.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ab3872-3da8-4f5f-9331-b72a4ddbd472",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 统计该csv下lable列不同值的数量\n",
    "train_csv.value_counts(subset=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d370b09-9821-4109-991c-493c0954b27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 画图显示类别数\n",
    "plt.bar([0,1,2,3],list(train_csv.value_counts(subset=\"label\")),tick_label = [\"0\",\"1\",\"2\",\"3\"])\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Num\")\n",
    "plt.title(\"Train dataset sample distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed34abe-0e67-425a-9062-63caa57a3f90",
   "metadata": {},
   "source": [
    "## 3、读取CSV文件、分离文件路径、文本内容、标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c77b828-131d-46af-8dfb-ef006ab58617",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 读取train.csv、dev.csv\n",
    "train_csv = pd.read_csv(\"./CSVfile/train.csv\", sep = \"#\")\n",
    "dev_csv = pd.read_csv(\"./CSVfile/dev.csv\", sep = \"#\")\n",
    "## 分离文件路径、文本内容和标签\n",
    "## 训练时间较长，建议可以先截取部分样本进行代码正确性验证，再使用全部样本\n",
    "train_path = list(train_csv.path)[:1500]\n",
    "train_label = list(train_csv.label)[:1500]\n",
    "train_txt = list(train_csv.text)[:1500]\n",
    "dev_path = list(dev_csv.path)[:500]\n",
    "dev_label = list(dev_csv.label)[:500]\n",
    "dev_txt = list(dev_csv.text)[:500]\n",
    "\n",
    "# train_path = list(train_csv.path)\n",
    "# train_label = list(train_csv.label)\n",
    "# train_txt = list(train_csv.text)\n",
    "# dev_path = list(dev_csv.path)\n",
    "# dev_label = list(dev_csv.label)\n",
    "# dev_txt = list(dev_csv.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf605b1d-02c1-4170-9f20-2c1fbd2c5fa9",
   "metadata": {},
   "source": [
    "## 4、创建Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884d5b66-08ad-41ab-8d97-5e8bf58554fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  'input_ids' 'token_type_ids' 'attention_mask'\n",
    "train_coded_txt = text_tokenize(train_txt)\n",
    "dev_coded_txt = text_tokenize(dev_txt)\n",
    "train_dataset = TensorDataset(train_coded_txt[\"input_ids\"], \n",
    "                              train_coded_txt[\"attention_mask\"],\n",
    "                              torch.tensor(train_label))\n",
    "dev_dataset = TensorDataset(dev_coded_txt[\"input_ids\"], \n",
    "                            dev_coded_txt[\"attention_mask\"],\n",
    "                            torch.tensor(dev_label))\n",
    "print(len(train_dataset),len(dev_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9543205c-c791-4c6e-854b-3259fa157d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255e8a1b-4acb-4635-ad08-91d1484bfa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 这里的batch_size 可以从1、2、4、8、16...尝试，过大的batch_size会使训练过程因为显存不足失败\n",
    "batch_size = 4\n",
    "dataloader_train = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=RandomSampler(train_dataset),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "dataloader_dev = DataLoader(\n",
    "    dev_dataset,\n",
    "    sampler=RandomSampler(dev_dataset),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162b55df-78fe-4b32-aaff-fb9884d5eb01",
   "metadata": {},
   "source": [
    "## 5、定义性能指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bf52fb-ddab-448c-9470-a73e4ba69841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c38fca-365c-4508-a6a3-712f612d40b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d689ef-f77c-476d-b004-5a88644761db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {0:\"angry\",1:\"happy or excited\",2:\"neutral\",3:\"sad\"}\n",
    "    # print(preds)\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76deef61-cee4-4074-ae9d-af2e6050e508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02602577-f76d-4c08-ba66-be8feddecb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score_classification(preds, labels, average_f1='macro'):  # weighted, macro\n",
    "    preds = np.argmax(preds, axis=1).flatten()\n",
    "    labels = labels.flatten()\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average=average_f1, zero_division=0)\n",
    "    precision = precision_score(labels, preds, average='macro', zero_division=0)\n",
    "    ua = recall_score(labels, preds, average='macro', zero_division=0)\n",
    "    confuse_matrix = confusion_matrix(labels, preds)\n",
    "    return accuracy, ua, f1, precision, confuse_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cb1bd0-dee0-4401-a8c7-d96c7bad44d5",
   "metadata": {},
   "source": [
    "## 6、设置模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9e9e08-f3ad-4d2f-8de9-4e7b21f6882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f920957a-b873-4047-a011-ac2c6fdc0330",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 创建深度学习模型类\n",
    "class MyDLmodel():\n",
    "    def __init__(self,model,device):\n",
    "        self.model = model\n",
    "        self.model.to(device)\n",
    "        self.optimizer = AdamW(self.model.parameters(),\n",
    "                               lr=1e-6,\n",
    "                               eps=1e-8)\n",
    "        self.scheduler = None\n",
    "        self.device = device\n",
    "    def evaluate(self,dataloader_val):\n",
    "        pass\n",
    "    def train(self,dataloader_train,dataloader_dev,epochs):\n",
    "        pass\n",
    "    def predict(self,dataloader_test):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec75a77-4152-49ab-9cc4-4433fdbacd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "## 设置随机种子\n",
    "def set_seeds(seed_val):\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af464655-26d5-43e1-89a0-29bda65bf7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test_preds 长度为1241的list，对应测试集中1241个样本的标签\n",
    "##运行后会在当前目录生成result.csv文件，提交result.csv文件即可\n",
    "##如果没有生成，请检查test_preds的长度是否为1241！\n",
    "def write_result(test_preds):\n",
    "    if len(test_preds) != 1241:\n",
    "        print(\"错误！请检查test_preds长度是否为1241！！！\")\n",
    "        return -1\n",
    "    test_csv = pd.read_csv(\"./CSVfile/test.csv\",sep=\"#\")\n",
    "    test_csv[\"label\"] = test_preds\n",
    "    test_csv.to_csv(\"./result.csv\",sep = \"#\")\n",
    "    print(\"测试集预测结果已成功写入到文件中！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cefe5b8-71e0-4a1a-bdae-a6673b02edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f388d7c-9451-462b-8fac-6c49ee431ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 特征处理函数，可以对提取的特征进行处理，以获得更好的特征表示\n",
    "def feature_process(feature):\n",
    "    return feature\n",
    "## model reference： https://huggingface.co/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification\n",
    "if __name__  == \"__main__\":\n",
    "    set_seeds(17)\n",
    "    pretrained_model = None\n",
    "    ## 这里的模型请自行寻找合适的多模态处理模型，以及考虑如何将多个模态的特征进行融合\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    mymodel = MyDLmodel(pretrained_model,device)\n",
    "    epochs = 10\n",
    "    mymodel.train(dataloader_train,dataloader_dev,epochs)\n",
    "    ## 预测测试集标签\n",
    "    test_csv = pd.read_csv(\"./CSVfile/test.csv\",sep = \"#\")\n",
    "    test_text = list(test_csv.text)\n",
    "    test_coded_txt = text_tokenize(test_text)\n",
    "    test_dataset = TensorDataset(\n",
    "        test_coded_txt[\"input_ids\"], \n",
    "        test_coded_txt[\"attention_mask\"])\n",
    "    dataloader_test = DataLoader(\n",
    "        test_dataset,\n",
    "        sampler=RandomSampler(test_dataset),\n",
    "        batch_size=32)\n",
    "    test_preds = mymodel.predict(dataloader_test)\n",
    "    ## 写入预测结果\n",
    "    write_result(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea31408-75f8-4e1f-bf0a-dde019047b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
